[toc]

## 请简述ILP、SMT（超线程）、CMP、SMP概念

### ILP - 指令级并行

流水线上的实际CPI(平均每条指令使用的周期数) ， 等于理想流水线的CPI加上由于各类停顿引起的周期数的总和。
$$
CPI_{流水线} = CPI_{结构相关}+CPI_{控制相关}+CPI_{RAW}+CPI_{WAR}+CPI_{WAW}
$$

#### 什么是指令级并行 - ILP

当指令中不存在相关时，他们在流水线上可以重叠执行的，我们重叠执行指令以提高性能。而这种指令序列存在的潜在并行性称为指令级并行

通常使用静态开发（依赖软件）和动态开发（依赖硬件）

#### 什么是基本块

基本块【BASE BLOCK】除了出口和入口没有其他分支的线性指令序列

#### 各类相关与冲突的关系

##### 数据相关 - Data Dependence

对于指令i和指令j，若

1. 指令j使用指令i的结果
2. 指令j与指令k数据相关，指令k与指令i数据相关，则指令j与指令i之间数据相关

其中第二条表明，数据相关具有传递性。数据相关时两条指令之间存在一个先读后写的相关链，这个相关链应该贯穿整个程序，是程序的内在特征，即数据相关是程序相关性最本质的相关之一。但这种相关性是导致流水线暂停的原因之一，因为相关的两条指令是不能够重叠执行的。

==相关性是程序的特征；冲突是流水线结构的特性；相关性的存在只预示着存在有冲突的可能性==

数据相关的重要性：

1. 确定指令的相关性，找到所有可能产生停顿的地方，预测冲突的可能性
2. 确定必须严格遵守的数据计算顺序
3. 决定可被开发的并行性的上界

##### 名相关

指令使用的寄存器或存储器称为名。如果两条指令使用的是相同的名，但是它们之间没有数据流，，则称之为名相关。

指令i和指令j的名相关分为两种：

1. 反相关：指令i先执行，指令j写的是指令i读的名，反相关指令之间的执行顺序是保证的。反相关的就是先读后写相关（WAR相关）。
2. 输出相关：指令i和指令j写的是同样的名。输出相关指令之间的执行顺序是不允许颠倒的。输出相关就是写后协相关（WAW相关）。

解决方式：与数据相关比较，名相关之间的指令没有数据交换。如果一条指令中的名改变了，并不影响另外一条指令的执行，因此可以改变指令中操作数的名来消除名相关，这就是换名技术。对寄存器来说这就是寄存器换名技术。这个过程既可以用编译器静态完成，也可以通过硬件动态完成。

##### 控制相关

控制相关是指由分支指令引起的相关，他需要根据分支指令执行的结果来确定后续指令执行的顺序。控制相关与分支成功或分支不成功两个基本程序块的执行有关，典型的程序结构是‘if-then’结构。
控制相关决定了指令执行的顺序。

```cpp
if p1 {
	S1;
};
if p2 {
	S2;
}
```

其中S1就和p1控制相关，S2和p2控制相关,S与p1和p2都控制无关。
处理控制相关有以下两个原则：

1. 与控制相关的指令不能移动到分支指令之前，即控制相关的指令不能调度到分支指令控制范围之外。
2. 与控制无关的指令不能移动到分支指令之后，即控制无关的指令不能调度到分支指令控制范围之内。

#### 参考资料

https://blog.csdn.net/angus_huang_xu/article/details/105746450

https://zhuanlan.zhihu.com/p/165400707

https://blog.csdn.net/Najlepszy/article/details/83961991

### SMT - 超线程

Intel Hyper-Threading Technology（超线程技术）的学术名字是Simulate MultiThreading（SMT，同步多线程技术），SMT是超线程技术的学术名称。这技术的引入是为了更好的利用CPU的空闲资源，Intel从奔腾处理器就开始引入超标量、乱序运行、大量的寄存器及寄存器重命名、多指令解码器、预测运行等特性，这些特性的原理是让CPU拥有大量资源，并可以预先运行及平行运行指令，以增加指令运行效率，可是在现实中这些资源经常闲置，为了有效利用这些资源，就干脆再增加一些资源来运行第二个线程，让这些闲置资源可运行另一个线程。

多线程有两个主要实现方法，一个是Temporal MultiThreading时间多线程，另一个则是Simulate MultiThreading同步多线程，时间多线程还可以进一步分为Fine-Grained MultiThreading细粒度多线程与Coarse-Grained MultiThreading粗粒度多线程。

![img](http://hz-picbed-xxh.oss-cn-hangzhou.aliyuncs.com/img-bed/20200322171007227.png)

CMT粗粒度多线程是最简单的多线程技术，当单一执行线程遇到长时间的延迟，如Cache Missed时，就进行线程切换，直到原线程等待的操作完成，才切换回去。

FMT细粒度多线程比CMT粗粒度多线程复杂一些，它随时可以在每个时钟周期内切换多个线程，以追求最大的输出能力，当然，随时可以切换也是有代价的，它拉长了每个执行线程的平均执行时间。

CMT和FMT都没有在消费级处理器上面使用，Intel与AMD处理器上使用的都是SMT同步多线程，不过NVIDIA与AMD的GPU都有使用FMT技术。

SMT同步多线程具有多个执行单元，CMT和FMT都是在单个执行单元下的技术，不同的线程在指令级别上并不是真正的“并行”，而SMT则具有多个执行单元，同一时间内可以同时执行多个指令，可以充分发掘超标量处理器的潜力，因此SMT具有最大的灵活性和资源利用率，不过处理器也更复杂。

不过现在的消费级处理器都是超标量处理器，所以要支持SMT其实在架构上不用太多改变：所需的主要添加是在一个周期中从多个线程获取指令的能力，以及一个更大的寄存器文件来保存来自多个线程的数据。并发线程的数量可以由芯片设计者决定。常见模式是每个CPU核心有两个并发线程，但一些处理器的每个核心支持最多八个并发线程。

对于单一处理器核心来说来说，虽然也可以每秒钟处理成千上万条指令，但是在某一时刻，只能够对一条指令(单个线程)进行处理，超线程技术能够 把一个物理处理器在软件层变成两个逻辑处理器 ，可以使处理器在某一时刻，同步并行处理更多指令和数据(多个线程)，当然了实际效能不可实现双倍提升，毕竟干活的核心只有一个。

![img](http://hz-picbed-xxh.oss-cn-hangzhou.aliyuncs.com/img-bed/20200322171203842.jpg)

可以这样说，超线程是一种可以将CPU内部暂时闲置处理资源充分“调动”起来的技术，奔腾4 HT处理器多加入了一个逻辑处理单元，这让CPU可以同时执行多个程序而共享一颗CPU内的资源，如：ALU、FPU、 缓存等，当两个线程都同时需要某一个资源时，其中一个要暂时停止，并让出资源，直到这些资源闲置后才能继续，因此超线程的性能并不等于两颗CPU的性能。

#### 参考资料

https://blog.csdn.net/qq_39820671/article/details/105031018

https://www.expreview.com/56674.html

### CMP - 单芯片多处理器

单芯片多处理器（Chip multiprocessors，简称CMP），也指多核心。CMP是由美国斯坦福大学提出的，其思想是将大规模并行处理器中的SMP（对称多处理器）集成到同一芯片内，各个处理器并行执行不同的进程。与CMP比较， SMT处理器结构的灵活性比较突出。但是，当半导体工艺进入0.18微米以后，线延时已经超过了门延迟，要求微处理器的设计通过划分许多规模更小、局部性更好的基本单元结构来进行。相比之下，由于CMP结构已经被划分成多个处理器核来设计，每个核都比较简单，有利于优化设计，因此更有发展前途。IBM 的Power 4芯片和Sun的 MAJC5200芯片都采用了CMP结构。多核处理器可以在处理器内部共享缓存，提高缓存利用率，同时简化多处理器系统设计的复杂度

### SMP - 对称多处理

对称多处理"（Symmetrical Multi-Processing）简称SMP，是指在一个计算机上汇集了一组处理器(多CPU),各CPU之间共享内存子系统以及总线结构。它是相对非对称多处理技术而言的、应用十分广泛的并行技术。

在这种架构中，一台电脑不再由单个CPU组成，而同时由多个处理器运行操作系统的单一复本，并共享内存和一台计算机的其他资源。虽然同时使用多个CPU，但是从管理的角度来看，它们的表现就像一台单机一样。系统将任务队列对称地分布于多个CPU之上，从而极大地提高了整个系统的数据处理能力。所有的处理器都可以平等地访问内存、I/O和外部中断。在对称多处理系统中，系统资源被系统中所有CPU共享，工作负载能够均匀地分配到所有可用处理器之上。

## 描述O0、O1、O2、O3优化差异

从代码的整体优化上，GCC提供了下面的选项

### -O –O1

这两个选项的含义是一样的，GCC将执行减少代码尺寸和执行时间的优化，对于那些会严重影响编译时间的优化选项，这个级别的优化并不会执行。

### -O2

在这一级别GCC将会提供所有支持的优化，但这其中并不包括以空间换时间的优化手段，例如编译器不会使用循环展开和函数内联。和-O相比，该选项进一步加快了编译时间和生成代码的性能。

### -O3

除了-O2提供的优化选项外，还指定了-finline-functions，-funswitch-loops和-fgcse-afer-reload选项，目的只有一个就是全力执行代码优化。

### -Os

这个选项是专门用来优化代码尺寸的，-Os打开了所有-O2级别中不会显著增长代码尺寸的优化选项

### -O0

该选项代表不执行优化

在这里要说明的是，尽管GCC提供了1~3和s这4个整体优化选项，但从实际的优化效果上来看，往往O3优化出来的程序的效率并不是最高的，而大部分情况下我们都在使用-O2，如果你希望获得最高的效率利益，那么不妨这4个选项都试试。另外，其实这些选项只不过是GCC提供的很多单方面优化的一个组合，如果你想了解更为具体的优化内容，可以去查看GCC手册，出于篇幅限制，这里不细谈了。最后要记住的一点是，如果你的程序是用于高精度数值计算的，那么记住不要使用上面任何的优化选项。

### gcc -O0 -O1 -O2 -O3 四级优化选项及每级分别做什么优化

gcc 提供了为了满足用户不同程度的的优化需要，提供了近百种优化选项，用来对{编译时间，目标文件长度，执行效率}这个三维模型进行不同的取舍和平衡。优化的方法不一而足，总体上将有以下几类：1）精简操作指令；2）尽量满足cpu的流水操作；3）通过对程序行为地猜测，重新调整代码的执行顺序；4）充分使用寄存器；5）对简单的调用进行展开等等。想全部了解这些编译选项，并在其中挑选适合的选项进行优化，无疑像个噩梦般的过程。单从gnu的官方网站上得到的手册来看，描述依然比较苍白，不足以完全了解选项的使用范围和原理。

幸而gcc提供了从O0-O3以及Os这几种不同的优化级别供大家选择，在这些选项中，包含了大部分有效的编译优化选项，并且可以在这个基础上，对某些选项进行屏蔽或添加，从而大大降低了使用的难度，毕竟，在一定基础上进行取舍，比万事从头开始要好得多。下面着重围绕这几个不同的级别进行简单介绍。（由于gcc不同版本手册差异比较大，以下主要以gcc-3.4.6为参考） 

#### -O0： 

不做任何优化，这是默认的编译选项。 

#### -O和-O1： 

对程序做部分编译优化，对于大函数,优化编译占用稍微多的时间和相当大的内存。使用本项优化，编译器会尝试减小生成代码的尺寸，以及缩短执行时间，但并不执行需要占用大量编译时间的优化。 

##### 打开的优化选项： 

l -fdefer-pop：延迟栈的弹出时间。当完成一个函数调用，参数并不马上从栈中弹出，而是在多个函数被调用后，一次性弹出。 

l -fmerge-constants：尝试横跨编译单元合并同样的常量(string constants and floating point constants) 

l -fthread-jumps：如果某个跳转分支的目的地存在另一个条件比较,而且该条件比较包含在前一个比较语句之内,那么执行本项优化.根据条件是true或者false,前面那条分支重定向到第二条分支的目的地或者紧跟在第二条分支后面. 

l -floop-optimize：执行循环优化,将常量表达式从循环中移除，简化判断循环的条件，并且optionally do strength-reduction，或者将循环打开等。在大型复杂的循环中，这种优化比较显著。 

l -fif-conversion：尝试将条件跳转转换为等价的无分支型式。优化实现方式包括条件移动，min，max，设置标志，以及abs指令，以及一些算术技巧等。  

l -fif-conversion2基本意义相同，没有找到更多的解释。 

l -fdelayed-branch：这种技术试图根据指令周期时间重新安排指令。 它还试图把尽可能多的指令移动到条件分支前, 以便最充分的利用处理器的治理缓存。 

l -fguess-branch-probability：当没有可用的profiling feedback或__builtin_expect时，编译器采用随机模式猜测分支被执行的可能性，并移动对应汇编代码的位置，这有可能导致不同的编译器会编译出迥然不同的目标代码。 

l -fcprop-registers：因为在函数中把寄存器分配给变量, 所以编译器执行第二次检查以便减少调度依赖性(两个段要求使用相同的寄存器)并且删除不必要的寄存器复制操作。 

#### -O2： 

是比O1更高级的选项，进行更多的优化。Gcc将执行几乎所有的不包含时间和空间折中的优化。当设置O2选项时，编译器并不进行循环打开（）loop unrolling以及函数内联。与O1比较而言，O2优化增加了编译时间的基础上，提高了生成代码的执行效率。 

##### O2打开所有的O1选项，并打开以下选项： 

l -fforce-mem：在做算术操作前，强制将内存数据copy到寄存器中以后再执行。这会使所有的内存引用潜在的共同表达式，进而产出更高效的代码，当没有共同的子表达式时，指令合并将排出个别的寄存器载入。这种优化对于只涉及单一指令的变量, 这样也许不会有很大的优化效果. 但是对于再很多指令(必须数学操作)中都涉及到的变量来说, 这会时很显著的优化, 因为和访问内存中的值相比 ,处理器访问寄存器中的值要快的多。 

l -foptimize-sibling-calls：优化相关的以及末尾递归的调用。通常, 递归的函数调用可以被展开为一系列一般的指令， 而不是使用分支。 这样处理器的指令缓存能够加载展开的指令并且处理他们, 和指令保持为需要分支操作的单独函数调用相比, 这样更快。 

l -fstrength-reduce：这种优化技术对循环执行优化并且删除迭代变量。 迭代变量是捆绑到循环计数器的变量, 比如使用变量, 然后使用循环计数器变量执行数学操作的for-next循环。 

l -fcse-follow-jumps：在公用子表达式消元时，当目标跳转不会被其他路径可达，则扫描整个的跳转表达式。例如，当公用子表达式消元时遇到if...else...语句时，当条为false时，那么公用子表达式消元会跟随着跳转。   

l -fcse-skip-blocks：与-fcse-follow-jumps类似，不同的是，根据特定条件，跟随着cse跳转的会是整个的blocks 

l -frerun-cse-after-loop：在循环优化完成后，重新进行公用子表达式消元操作。 

l -frerun-loop-opt：两次运行循环优化 l -fgcse：执行全局公用子表达式消除pass。这个pass还执行全局常量和copy propagation。这些优化操作试图分析生成的汇编语言代码并且结合通用片段， 消除冗余的代码段。如果代码使用计算性的goto, gcc指令推荐使用-fno-gcse选项。 

l-fgcse-lm：全局公用子表达式消除将试图移动那些仅仅被自身存储kill的装载操作的位置。这将允许将循环内的load/store操作序列中的load转移到循环的外面（只需要装载一次），而在循环内改变成copy/store序列。在选中-fgcse后，默认打开。 

l -fgcse-sm：当一个存储操作pass在一个全局公用子表达式消除的后面，这个pass将试图将store操作转移到循环外面去。如果与-fgcse-lm配合使用，那么load/store操作将会转变为在循环前load，在循环后store，从而提高运行效率，减少不必要的操作。 

l -fgcse-las：全局公用子表达式消除pass将消除在store后面的不必要的load操作，这些load与store通常是同一块存储单元（全部或局部） 

l-fdelete-null-pointer-checks：通过对全局数据流的分析，识别并排出无用的对空指针的检查。编译器假设间接引用空指针将停止程序。 如果在间接引用之后检查指针，它就不可能为空。 

l -fexpensive-optimizations：进行一些从编译的角度来说代价高昂的优化（这种优化据说对于程序执行未必有很大的好处，甚至有可能降低执行效率，具体不是很清楚） 

l -fregmove：编译器试图重新分配move指令或者其他类似操作数等简单指令的寄存器数目，以便最大化的捆绑寄存器的数目。这种优化尤其对双操作数指令的机器帮助较大。 

l -fschedule-insns：编译器尝试重新排列指令，用以消除由于等待未准备好的数据而产生的延迟。这种优化将对慢浮点运算的机器以及需要load memory的指令的执行有所帮助，因为此时允许其他指令执行，直到load memory的指令完成，或浮点运算的指令再次需要cpu。 l 

-fschedule-insns2：与-fschedule-insns相似。但是当寄存器分配完成后，会请求一个附加的指令计划pass。这种优化对寄存器较小，并且load memory操作时间大于一个时钟周期的机器有非常好的效果。 

l -fsched-interblock：这种技术使编译器能够跨越指令块调度指令。 这可以非常灵活地移动指令以便等待期间完成的工作最大化。 

l -fsched-spec-load：允许一些load指令进行一些投机性的动作。（具体不详）相同功能的还有-fsched-spec-load-dangerous，允许更多的load指令进行投机性操作。这两个选项在选中-fschedule-insns时默认打开。 

l -fcaller-saves：通过存储和恢复call调用周围寄存器的方式，使被call调用的value可以被分配给寄存器，这种只会在看上去能产生更好的代码的时候才被使用。（如果调用多个函数, 这样能够节省时间, 因为只进行一次寄存器的保存和恢复操作, 而不是在每个函数调用中都进行。） 

l -fpeephole2：允许计算机进行特定的观察孔优化(这个不晓得是什么意思)，-fpeephole与-fpeephole2的差别在于不同的编译器采用不同的方式，由的采用-fpeephole，有的采用-fpeephole2，也有两种都采用的。 

l -freorder-blocks：在编译函数的时候重新安排基本的块，目的在于减少分支的个数，提高代码的局部性。 

l -freorder-functions：在编译函数的时候重新安排基本的块，目的在于减少分支的个数，提高代码的局部性。这种优化的实施依赖特定的已存在的信息：.text.hot用于告知访问频率较高的函数，.text.unlikely用于告知基本不被执行的函数。 

l -fstrict-aliasing：这种技术强制实行高级语言的严格变量规则。 对于c和c++程序来说, 它确保不在数据类型之间共享变量. 例如, 整数变量不和单精度浮点变量使用相同的内存位置。 

l -funit-at-a-time：在代码生成前，先分析整个的汇编语言代码。这将使一些额外的优化得以执行，但是在编译器间需要消耗大量的内存。（有资料介绍说：这使编译器可以重新安排不消耗大量时间的代码以便优化指令缓存。） 

l -falign-functions：这个选项用于使函数对准内存中特定边界的开始位置。 大多数处理器按照页面读取内存，并且确保全部函数代码位于单一内存页面内, 就不需要叫化代码所需的页面。 

l -falign-jumps：对齐分支代码到2的n次方边界。在这种情况下，无需执行傀儡指令（dummy operations） 

l -falign-loops：对齐循环到2的n次幂边界。期望可以对循环执行多次，用以补偿运行dummy operations所花费的时间。 

l -falign-labels：对齐分支到2的n次幂边界。这种选项容易使代码速度变慢，原因是需要插入一些dummy operations当分支抵达usual flow of the code. 

l -fcrossjumping：这是对跨越跳转的转换代码处理， 以便组合分散在程序各处的相同代码。 这样可以减少代码的长度， 但是也许不会对程序性能有直接影响。  

#### -O3： 

比O2更进一步的进行优化。

##### 在包含了O2所有的优化的基础上，又打开了以下优化选项： 

l -finline-functions：内联简单的函数到被调用函数中。由编译器启发式的决定哪些函数足够简单可以做这种内联优化。默认情况下，编译器限制内联的尺寸，3.4.6中限制为600（具体含义不详，指令条数或代码size？）可以通过-finline-limit=n改变这个长度。这种优化技术不为函数创建单独的汇编语言代码， 而是把函数代码包含在调度程序的代码中。 对于多次被调用的函数来说, 为每次函数调用复制函数代码。 虽然这样对于减少代码长度不利, 但是通过最充分的利用指令缓存代码, 而不是在每次函数调用时进行分支操作, 可以提高性能。 

l -fweb：构建用于保存变量的伪寄存器网络。 伪寄存器包含数据, 就像他们是寄存器一样, 但是可以使用各种其他优化技术进行优化, 比如cse和loop优化技术。这种优化会使得调试变得更加的不可能，因为变量不再存放于原本的寄存器中。 

l -frename-registers：在寄存器分配后，通过使用registers left over来避免预定代码中的虚假依赖。这会使调试变得非常困难，因为变量不再存放于原本的寄存器中了。 

l -funswitch-loops：将无变化的条件分支移出循环，取而代之的将结果副本放入循环中。 

####  -Os： 

主要是对程序的尺寸进行优化。打开了大部分O2优化中不会增加程序大小的优化选项，并对程序代码的大小做更深层的优化。（通常我们不需要这种优化）Os会关闭如下选项： -falign-functions -falign-jumps -falign-loops  -falign-labels   -freorder-blocks   -fprefetch-loop-arrays  

优化介绍小结 O0选项不进行任何优化，在这种情况下，编译器尽量的缩短编译消耗（时间，空间），此时，debug会产出和程序预期的结果。当程序运行被断点打断，此时程序内的各种声明是独立的，我们可以任意的给变量赋值，或者在函数体内把程序计数器指到其他语句,以及从源程序中 精确地获取你期待的结果. 

O1优化会消耗少多的编译时间，它主要对代码的分支，常量以及表达式等进行优化。 

O2会尝试更多的寄存器级的优化以及指令级的优化，它会在编译期间占用更多的内存和编译时间。 

O3在O2的基础上进行更多的优化，例如使用伪寄存器网络，普通函数的内联，以及针对循环的更多优化。 

Os主要是对代码大小的优化，我们基本不用做更多的关心。 通常各种优化都会打乱程序的结构，让调试工作变得无从着手。并且会打乱执行顺序，依赖内存操作顺序的程序需要做相关处理才能确保程序的正确性。  

优化代码有可能带来的问题 

1．调试问题：正如上面所提到的，任何级别的优化都将带来代码结构的改变。例如：对分支的合并和消除，对公用子表达式的消除，对循环内load/store操作的替换和更改等，都将会使目标代码的执行顺序变得面目全非，导致调试信息严重不足。 

2．内存操作顺序改变所带来的问题：在O2优化后，编译器会对影响内存操作的执行顺序。例如：-fschedule-insns允许数据处理时先完成其他的指令；-fforce-mem有可能导致内存与寄存器之间的数据产生类似脏数据的不一致等。对于某些依赖内存操作顺序而进行的逻辑，需要做严格的处理后才能进行优化。例如，采用volatile关键字限制变量的操作方式，或者利用barrier迫使cpu严格按照指令序执行的。

#### 参考资料

https://blog.csdn.net/qq_31108501/article/details/51842166

https://blog.csdn.net/qq_45596259/article/details/101192974

https://blog.csdn.net/Sodier/article/details/452566

## 请仔细分析中断向量表如何构建的

中断向量:是指中断服务程序入口地址的偏移量与段基值，一个中断向量占据4字节空间。中断向量表是8088系统内存中最低端1K字节空间，它的作用就是按照中断类型号从小到大的顺序存储对应的中断向量，总共存储256个中断向量。在中断响应过程中，CPU通过从接口电路获取的中断类型号（中断向量号）计算对应中断向量在表中的位置，并从中断向量表中获取中断向量，将程序流程转向中断服务程序的入口地址。

80x86系统是把所有的中断向量集中起来，按中断类型号从小到大的顺序存放到存储器的某一区域内，这个存放中断向量的存储区叫做中断向量表，即中断服务程序入口地址表。

由于中断向量表可以在操作系统层面灵活修改，因此，不同的系统的中断向量表可能是不同的。此外，intel在CPU的保护模式下，占用了0x00 ~ 0x1F共32个中断号，在Linux下，是从0x20开始用于系统自身的中断的，包括8259芯片的中断重置。

ARM linux内核启动时，通过start_kernel()->trap_init()的调用关系，初始化内核的中断异常向量表．

```c
／* arch/arm/kernel/traps.c */
void __init trap_init(void)
{
   extern void __trap_init(unsigned long);
   unsigned long base = vectors_base();

   __trap_init(base);
   if (base != 0)
      oopsprintk(KERN_DEBUG "Relocating machine vectors to 0x%08lx/n", base);
#ifdef CONFIG_CPU_32
modify_domain(DOMAIN_USER, DOMAIN_CLIENT);
#endif
}
```

 vectors_base是一个宏，它的作用是获取ARM异常向量的地址，该宏在include/arch/asm-arm/proc-armv/system.h中定义：

```c
extern unsigned long cr_no_alignment; /* defined in entry-armv.S */
extern unsigned long cr_alignment; /* defined in entry-armv.S */

#if __LINUX_ARM_ARCH__ >= 4
#define vectors_base() ((cr_alignment & CR_V) ? 0xffff0000 : 0)
#else
#define vectors_base() (0)
#endif
```

　对于ARMv4以下的版本，这个地址固定为0；ARMv4及其以上的版本，ARM异常向量表的地址受协处理器CP15的c1寄存器 (control register)中V位(bit[13])的控制，如果V=1，则异常向量表的地址为0x00000000~0x0000001C；如果V=0,则 为:0xffff0000~0xffff001C。（详情请参考ARM Architecture Reference Manual)
下面分析一下cr_alginment的值是在哪确定的，我们在arch/arm/kernel/entry-armv.S找到cr_alignment的定义：

```c
.globl SYMBOL_NAME(cr_alignment)
                .globl SYMBOL_NAME(cr_no_alignment)
SYMBOL_NAME(cr_alignment):
                .space 4
SYMBOL_NAME(cr_no_alignment):
                .space 4
```

head-armv.S是非压缩内核的入口：

```c
 .section ".text.init",#alloc,#execinstr
ENTRY(stext)   
               mov     r12, r0
               
               mov     r0, #F_BIT | I_BIT | MODE_SVC   @ make sure svc mode
               msr     cpsr_c, r0                      @ and all irqs disabled
               bl      __lookup_processor_type        
               teq     r10, #0                         @ invalid processor?
               moveq   r0, #'p'                        @ yes, error 'p'
               beq     __error
               bl      __lookup_architecture_type
               teq     r7, #0                          @ invalid architecture?
               moveq   r0, #'a'                        @ yes, error 'a'
               beq     __error
               bl      __create_page_tables           
               adr     lr, __ret                       @ return address
               add     pc, r10, #12                    @ initialise processor
                                                       @ (return control reg)

               .type   __switch_data, %object
__switch_data: .long   __mmap_switched
               .long   SYMBOL_NAME(__bss_start)
                .long   SYMBOL_NAME(_end)
               .long   SYMBOL_NAME(processor_id)
                .long   SYMBOL_NAME(__machine_arch_type)
                .long   SYMBOL_NAME(cr_alignment)
                .long   SYMBOL_NAME(init_task_union)+8192

               .type   __ret, %function
__ret:          ldr     lr, __switch_data
                mcr     p15, 0, r0, c1, c0
                mrc     p15, 0, r0, c1, c0, 0           @ read it back.
                mov     r0, r0
                mov     r0, r0
                mov     pc, lr
```

这里我们关心的是从17行开始，17行code处将lr放置为__ret标号处的相对地址，以便将来某处返回时跳转到31行继续运行；
18行,对于我所分析的pxa270平台，它将是跳转到arch/arm/mm/proc-xscale.S中执行__xscale_setup函数， 在__xscale_setup中会读取CP15的control register(c1)的值到r1寄存器，并在r1寄存器中设置相应的标志位（其中包括设置V位＝１），但在__xscale_setup中，r1寄存 器并不立即写回到Cp15的control register中，而是在返回后的某个地方，接下来会慢慢分析到。__xscale_setup调用move pc, lr指令返回跳转到31行。
31行，在lr寄存器中放置__switch_data中的数据__mmap_switched，在36行程序会跳转到__mmap_switched处。
32，33行，把r0寄存器中的值写回到cp15的control register(c1)中,再读出来放在r0中。

接下来再来看一下跳转到__mmap_switched处的代码：

```c
_mmap_switched:
                 adr     r3, __switch_data + 4
                 ldmia   r3, {r4, r5, r6, r7, r8, sp}@ r2 = compat
                                                        @ sp = stack pointer

                 mov     fp, #0                          @ Clear BSS (and zero fp)
_1:              cmp     r4, r5
                 strcc   fp, [r4],#4
                 bcc     1b

                 str     r9, [r6]                        @ Save processor ID
                 str     r1, [r7]                        @ Save machine type
                 bic     r2, r0, #2                      @ Clear 'A' bit
                 stmia   r8, {r0, r2}                    @ Save control register values
                 b       SYMBOL_NAME(start_kernel)
```

41~42行的结果是：r4=__bss_start，r5=__end,...,r8=cr_alignment,..,这里r8保存的是cr_alignment变量的地址．
到了53行，由于之前r0保存的是cp15的control register(c1)的值，这里把r0的值写入r8指向的地址，即cr_alignment=r0．到此为止，我们就看清楚了cr_alignment的赋值过程。

　　让我们回到trap_init()函数，经过上面的分析，我们知道vectors_base返回0xffff0000。函数__trap_init由汇编代码编写，在arch/arm/kernel/entry-arm.S：

```c
.align 5
__stubs_start:
vector_IRQ:
...
vector_data:
　　　　....
vector_prefetch:
...                                                                                                                       
vector_undefinstr:
...
vector_FIQ: disable_fiq
subs pc, lr, #4
vector_addrexcptn:
b vector_addrexcptn       
   　　　　...
__stubs_end:
   .equ __real_stubs_start, .LCvectors + 0x200

.LCvectors: swi SYS_ERROR0
   b __real_stubs_start + (vector_undefinstr - __stubs_start)
   ldr pc, __real_stubs_start + (.LCvswi - __stubs_start)
   b __real_stubs_start + (vector_prefetch - __stubs_start)
   b __real_stubs_start + (vector_data - __stubs_start)
   b __real_stubs_start + (vector_addrexcptn - __stubs_start)
   b __real_stubs_start + (vector_IRQ - __stubs_start)
   b __real_stubs_start + (vector_FIQ - __stubs_start)

ENTRY(__trap_init)
   　　　　stmfd sp!, {r4 - r6, lr}   /* 压栈，保存数据*/

   　　　　/* 复制异常向量表(.LCvectors起始的8个地址）到r0指向的地址（异常向量地址），r0就是__trap_init(base)函数调用时传递的参数，不明白的请参考ATPCS*/
   　　　　adr r1, .LCvectors    @ set up the vectors
   　　　　ldmia r1, {r1, r2, r3, r4, r5, r6, ip, lr}
   stmia r0, {r1, r2, r3, r4, r5, r6, ip, lr}
  
   /* 在异常向量地址后的0x200偏移处，放置散转代码，即__stubs_start~__stubs_end之间的各个异常处理代码*/
   add r2, r0, #0x200
   adr r0, __stubs_start   @ copy stubs to 0x200
   adr r1, __stubs_end
1:               ldr r3, [r0], #4
str r3, [r2], #4
cmp r0, r1
                  blt 1b
                  LOADREGS(fd, sp!, {r4 - r6, pc}) /*出栈，恢复数据，函数__trap_init返回*/

    __trap_init函数填充后的向量表如下：
    虚拟地址       异常              处理代码
    0xffff0000       reset              swi SYS_ERROR0
    0xffff0004      undefined       b __real_stubs_start + (vector_undefinstr - __stubs_start)
    0xffff0008      软件中断      ldr pc, __real_stubs_start + (.LCvswi - __stubs_start)
    0xffff000c      取指令异常   b __real_stubs_start + (vector_prefetch - __stubs_start)
    0xffff0010      数据异常      b __real_stubs_start + (vector_data - __stubs_start)
    0xffff0014      reserved         b __real_stubs_start + (vector_addrexcptn - __stubs_start)
    0xffff0018      irq                  b __real_stubs_start + (vector_IRQ - __stubs_start)
    0xffff001c      fiq                   b __real_stubs_start + (vector_FIQ - __stubs_start)
```

当有异常发生时，处理器会跳转到对应的0xffff0000起始的向量处取指令，然后，通过b指令散转到异常处理代码．因为ARM中b指令是相对跳转，而 且只有+/-32MB的寻址范围，所以把__stubs_start~__stubs_end之间的异常处理代码复制到了0xffff0200起始处．这 里可直接用b指令跳转过去，这样比使用绝对跳转（ldr)效率高。

#### 参考资料

https://blog.csdn.net/xiyangfan/article/details/5701673

https://tech.hqew.com/fangan_1727186

## 请简述stack、threadinfo、task_struct之间的关系。

在linux内核中进程以及线程（多线程也是通过一组轻量级进程实现的）都是通过task_struct结构体来描述的，我们称它为进程描述符。而thread_info则是一个与进程描述符相关的小数据结构，它同进程的内核态栈stack存放在一个单独为进程分配的内存区域。由于这个内存区域同时保存了thread_info和stack，所以使用了联合体来定义，相关数据结构如下（基于4.4.87版本内核）：

 thread_union联合体定义：

```c
union thread_union {
    struct thread_info thread_info;
    unsigned long stack[THREAD_SIZE/sizeof(long)];
};
```

thread_info结构体定义：

```c
struct thread_info {
    unsigned long        flags;        /* low level flags */
    mm_segment_t        addr_limit;    /* address limit */
    struct task_struct    *task;        /* main task structure */
    int            preempt_count;    /* 0 => preemptable, <0 => bug */
    int            cpu;        /* cpu */
};
```

task_struct的结构比较复杂，只列出部分成员变量

```c
struct task_struct {
    volatile long state;
    void *stack; 
　//...
#ifdef CONFIG_SMP
    int on_cpu;
    int wake_cpu;
#endif
    int on_rq;
 　//...
#ifdef CONFIG_SCHED_INFO
    struct sched_info sched_info;
#endif
　//... 
    pid_t pid;
    pid_t tgid;
　//...
}; 
```

这样设计的好处就是，得到stack，thread_info或task_struct任意一个数据结构的地址，就可以很快得到另外两个数据的地址。 而通过thread_info->task这个成员变量，又能访问到进程的task_struct结构体，这样就形成了task_struct, thread_info,stack三者之间的关系网，知道其中任何一个，都可以快速的访问到另外两个，提高了数据存取的效率。

#### 参考资料

https://www.cnblogs.com/yanghaizhou/p/7705520.html
